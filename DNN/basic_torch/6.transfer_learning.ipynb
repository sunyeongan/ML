{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac623d87-6003-48ab-9767-0215ba6a0ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchsummary\n",
      "  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
      "Installing collected packages: torchsummary\n",
      "Successfully installed torchsummary-1.5.1\n"
     ]
    }
   ],
   "source": [
    "! pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "574345a8-2600-498c-8078-cb03d21093b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abd97c50-88f0-413e-b918-f5089b09dd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a268d419-ee8e-4c1d-af29-cc636ee85276",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TheModelClass(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TheModelClass, self).__init__()\n",
    "                 \n",
    "        self.layer1 = nn.Sequential(\n",
    "        \t\t\tnn.Conv2d( 3, 16, kernel_size=3, stride=2, padding=0 ),\n",
    "                    nn.BatchNorm2d(16),\n",
    "                    nn.ReLU(),\n",
    "                    nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "                    \n",
    "        self.layer2 = nn.Sequential(\n",
    "        \t\t\tnn.Conv2d( 16, 32, kernel_size=3, stride=2, padding=0),\n",
    "                    nn.BatchNorm2d(32),\n",
    "                    nn.ReLU(),\n",
    "                    nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "                    \n",
    "        self.layer3 = nn.Sequential(\n",
    "        \t\t\tnn.Conv2d(32, 64, kernel_size=3, stride=2, padding=0),\n",
    "                    nn.BatchNorm2d(64),\n",
    "                    nn.ReLU(),\n",
    "                    nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "                    \n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.fc1 = nn.Linear(3*3*64, 1000)\n",
    "        self.fc2 = nn.Linear(1000,1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        \n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.drop_out(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "246c8a9a-a919-45ba-b6cf-ae440acf7881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 초기화\n",
    "model = TheModelClass().cuda()\n",
    "\n",
    "# optimizer 초기화\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b679821-d131-4fa8-aba4-384713b6c0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "layer1.0.weight \t torch.Size([16, 3, 3, 3])\n",
      "layer1.0.bias \t torch.Size([16])\n",
      "layer1.1.weight \t torch.Size([16])\n",
      "layer1.1.bias \t torch.Size([16])\n",
      "layer1.1.running_mean \t torch.Size([16])\n",
      "layer1.1.running_var \t torch.Size([16])\n",
      "layer1.1.num_batches_tracked \t torch.Size([])\n",
      "layer2.0.weight \t torch.Size([32, 16, 3, 3])\n",
      "layer2.0.bias \t torch.Size([32])\n",
      "layer2.1.weight \t torch.Size([32])\n",
      "layer2.1.bias \t torch.Size([32])\n",
      "layer2.1.running_mean \t torch.Size([32])\n",
      "layer2.1.running_var \t torch.Size([32])\n",
      "layer2.1.num_batches_tracked \t torch.Size([])\n",
      "layer3.0.weight \t torch.Size([64, 32, 3, 3])\n",
      "layer3.0.bias \t torch.Size([64])\n",
      "layer3.1.weight \t torch.Size([64])\n",
      "layer3.1.bias \t torch.Size([64])\n",
      "layer3.1.running_mean \t torch.Size([64])\n",
      "layer3.1.running_var \t torch.Size([64])\n",
      "layer3.1.num_batches_tracked \t torch.Size([])\n",
      "fc1.weight \t torch.Size([1000, 576])\n",
      "fc1.bias \t torch.Size([1000])\n",
      "fc2.weight \t torch.Size([1, 1000])\n",
      "fc2.bias \t torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "#모델 파라미터 출력\n",
    "\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "\tprint(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9c93840-4dff-4e39-93d2-9433c736ce61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 111, 111]             448\n",
      "       BatchNorm2d-2         [-1, 16, 111, 111]              32\n",
      "              ReLU-3         [-1, 16, 111, 111]               0\n",
      "         MaxPool2d-4           [-1, 16, 55, 55]               0\n",
      "            Conv2d-5           [-1, 32, 27, 27]           4,640\n",
      "       BatchNorm2d-6           [-1, 32, 27, 27]              64\n",
      "              ReLU-7           [-1, 32, 27, 27]               0\n",
      "         MaxPool2d-8           [-1, 32, 13, 13]               0\n",
      "            Conv2d-9             [-1, 64, 6, 6]          18,496\n",
      "      BatchNorm2d-10             [-1, 64, 6, 6]             128\n",
      "             ReLU-11             [-1, 64, 6, 6]               0\n",
      "        MaxPool2d-12             [-1, 64, 3, 3]               0\n",
      "          Dropout-13                  [-1, 576]               0\n",
      "           Linear-14                 [-1, 1000]         577,000\n",
      "           Linear-15                    [-1, 1]           1,001\n",
      "================================================================\n",
      "Total params: 601,809\n",
      "Trainable params: 601,809\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 5.53\n",
      "Params size (MB): 2.30\n",
      "Estimated Total Size (MB): 8.40\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9acd2f36-1e68-4bd9-a2de-ff8e6b5ca61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"saved\"\n",
    "\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "\tos.makedirs(MODEL_PATH)\n",
    "\n",
    "    # 모델의 파라미터 저장 \n",
    "torch.save(model.state_dict(),\n",
    "\t\t   os.path.join(MODEL_PATH, \"model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6437399-fd72-4684-b542-832b86b9d56c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "new_model = TheModelClass()\n",
    "# 모델 불러오기 -> 반드시 같은 아키텍처를 가져와야만 함 \n",
    "new_model.load_state_dict(torch.load(os.path.join(MODEL_PATH,\"model.pt\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5ea8488-87ef-4ce0-80c7-70ed85afe2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TheModelClass(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (drop_out): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=576, out_features=1000, bias=True)\n",
       "  (fc2): Linear(in_features=1000, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 전체를 저장 (pickle 이용)\n",
    "\n",
    "torch.save(model, os.path.join(MODEL_PATH, \"model_pickle.pt\"))\n",
    "model = torch.load(os.path.join(MODEL_PATH, \"model_pickle.pt\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fc1da8-c021-4cd6-9755-e351a755e7f5",
   "metadata": {},
   "source": [
    "### CheckPoints\n",
    "학습의 중간 결과를 저장해 최선의 결과를 선택 \n",
    "\n",
    "epoch, loss, metric 값을 지속적으로 확인 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a86942b-5a87-45e0-beed-cd4296ec62d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Destination path 'data\\PetImages' already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mError\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [10], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \tzip_ref\u001b[38;5;241m.\u001b[39mextractall()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmove\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPetImages\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m \n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m walk\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\pt_nlp\\lib\\shutil.py:823\u001b[0m, in \u001b[0;36mmove\u001b[1;34m(src, dst, copy_function)\u001b[0m\n\u001b[0;32m    820\u001b[0m     real_dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst, _basename(src))\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(real_dst):\n\u001b[1;32m--> 823\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Error(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDestination path \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m already exists\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m real_dst)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    825\u001b[0m     os\u001b[38;5;241m.\u001b[39mrename(src, real_dst)\n",
      "\u001b[1;31mError\u001b[0m: Destination path 'data\\PetImages' already exists"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import shutil \n",
    "\n",
    "filename = \"kagglecatsanddogs_5340.zip\"\n",
    "with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "\tzip_ref.extractall()\n",
    "    \n",
    "import shutil\n",
    "shutil.move('PetImages', 'data')\n",
    "\n",
    "import os \n",
    "from os import walk\n",
    "\n",
    "mypath = \"data\"\n",
    "\n",
    "f_path = []\n",
    "for (dirpath, dirnames, filenames) in walk(mypath):\n",
    "\tf_path.extend([os.path.join(dirpath, filename) for filename in filenames])\n",
    "    \n",
    "from PIL import Image\n",
    "\n",
    "# 유효하지 않은 파일들은 삭제 처리\n",
    "for f_name in f_path:\n",
    "    try:\n",
    "        Image.open(f_name)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        os.remove(f_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb0348c7-8198-4e8c-bb68-00c477b825cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\asy10\\\\ML\\\\DNN\\\\basic_torch'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "811f221d-2154-49b9-876c-cb33a88437c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch \n",
    "\n",
    "dataset = datasets.ImageFolder(root=\"./data/PetImages\",\n",
    "\t\t\t\ttransform=transforms.Compose([\n",
    "                transforms.Resize(244),\n",
    "                transforms.CenterCrop(244),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "        \t\t\t\t std = [0.5, 0.5, 0.5])\n",
    "                ]))\n",
    "                \n",
    "dataloader = torch.utils.data.DataLoader(dataset,batch_size=8,shuffle=True,num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a4aef6f-3140-4c9f-ac0c-ecaa2f5f63db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "    \n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc*100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ceae6c45-8589-4296-851e-ee4972cd6426",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c5a94924-5ade-4284-8466-d20309e7f656",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a226c23-3099-4e73-ab3b-4ce9bc794752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss 0.84544 | Acc : 49.795\n",
      "Epoch 002: | Loss 0.85836 | Acc : 50.386\n",
      "Epoch 003: | Loss 0.86080 | Acc : 50.347\n",
      "Epoch 004: | Loss 0.85563 | Acc : 50.037\n",
      "Epoch 005: | Loss 0.84687 | Acc : 50.131\n",
      "Epoch 006: | Loss 0.88031 | Acc : 49.939\n",
      "Epoch 007: | Loss 0.85371 | Acc : 49.816\n",
      "Epoch 008: | Loss 0.83743 | Acc : 50.083\n",
      "Epoch 009: | Loss 0.84291 | Acc : 49.828\n",
      "Epoch 010: | Loss 0.84589 | Acc : 50.033\n",
      "Epoch 011: | Loss 0.84697 | Acc : 49.832\n",
      "Epoch 012: | Loss 0.85747 | Acc : 49.812\n",
      "Epoch 013: | Loss 0.85328 | Acc : 49.745\n",
      "Epoch 014: | Loss 0.86010 | Acc : 49.730\n",
      "Epoch 015: | Loss 0.83031 | Acc : 49.862\n",
      "Epoch 016: | Loss 0.87708 | Acc : 50.385\n",
      "Epoch 017: | Loss 0.81394 | Acc : 50.158\n",
      "Epoch 018: | Loss 0.86267 | Acc : 49.496\n",
      "Epoch 019: | Loss 0.84285 | Acc : 50.022\n",
      "Epoch 020: | Loss 0.84047 | Acc : 50.180\n",
      "Epoch 021: | Loss 0.87165 | Acc : 49.263\n",
      "Epoch 022: | Loss 0.84765 | Acc : 49.863\n",
      "Epoch 023: | Loss 0.85097 | Acc : 50.342\n",
      "Epoch 024: | Loss 0.85121 | Acc : 50.583\n",
      "Epoch 025: | Loss 0.83390 | Acc : 50.246\n",
      "Epoch 026: | Loss 0.88642 | Acc : 49.924\n",
      "Epoch 027: | Loss 0.84111 | Acc : 49.830\n",
      "Epoch 028: | Loss 0.84302 | Acc : 50.196\n",
      "Epoch 029: | Loss 0.85015 | Acc : 50.052\n",
      "Epoch 030: | Loss 0.86519 | Acc : 49.507\n",
      "Epoch 031: | Loss 0.83178 | Acc : 49.452\n",
      "Epoch 032: | Loss 0.83376 | Acc : 49.700\n",
      "Epoch 033: | Loss 0.83828 | Acc : 49.825\n",
      "Epoch 034: | Loss 0.85054 | Acc : 50.070\n",
      "Epoch 035: | Loss 0.85822 | Acc : 49.790\n",
      "Epoch 036: | Loss 0.88636 | Acc : 49.917\n",
      "Epoch 037: | Loss 0.83774 | Acc : 49.606\n",
      "Epoch 038: | Loss 0.89032 | Acc : 50.239\n",
      "Epoch 039: | Loss 0.87413 | Acc : 49.597\n",
      "Epoch 040: | Loss 0.83100 | Acc : 49.844\n",
      "Epoch 041: | Loss 0.83787 | Acc : 50.516\n",
      "Epoch 042: | Loss 0.83936 | Acc : 49.654\n",
      "Epoch 043: | Loss 0.83926 | Acc : 50.605\n",
      "Epoch 044: | Loss 0.84556 | Acc : 49.548\n",
      "Epoch 045: | Loss 0.84920 | Acc : 50.072\n",
      "Epoch 046: | Loss 0.86627 | Acc : 49.806\n",
      "Epoch 047: | Loss 0.83806 | Acc : 49.614\n",
      "Epoch 048: | Loss 0.83532 | Acc : 50.098\n",
      "Epoch 049: | Loss 0.86229 | Acc : 49.686\n",
      "Epoch 050: | Loss 0.83685 | Acc : 50.133\n",
      "Epoch 051: | Loss 0.89054 | Acc : 50.121\n",
      "Epoch 052: | Loss 0.86038 | Acc : 49.908\n",
      "Epoch 053: | Loss 0.83935 | Acc : 49.390\n",
      "Epoch 054: | Loss 0.83638 | Acc : 50.304\n",
      "Epoch 055: | Loss 0.86594 | Acc : 50.200\n",
      "Epoch 056: | Loss 0.84130 | Acc : 49.773\n",
      "Epoch 057: | Loss 0.85666 | Acc : 49.968\n",
      "Epoch 058: | Loss 0.83393 | Acc : 49.901\n",
      "Epoch 059: | Loss 0.82861 | Acc : 50.424\n",
      "Epoch 060: | Loss 0.84359 | Acc : 49.993\n",
      "Epoch 061: | Loss 0.90994 | Acc : 50.143\n",
      "Epoch 062: | Loss 0.83857 | Acc : 49.449\n",
      "Epoch 063: | Loss 0.84902 | Acc : 50.534\n",
      "Epoch 064: | Loss 0.86145 | Acc : 49.980\n",
      "Epoch 065: | Loss 0.84676 | Acc : 50.152\n",
      "Epoch 066: | Loss 0.82888 | Acc : 50.173\n",
      "Epoch 067: | Loss 0.90148 | Acc : 50.302\n",
      "Epoch 068: | Loss 0.85491 | Acc : 50.053\n",
      "Epoch 069: | Loss 0.83752 | Acc : 49.812\n",
      "Epoch 070: | Loss 0.85262 | Acc : 50.471\n",
      "Epoch 071: | Loss 0.85186 | Acc : 49.581\n",
      "Epoch 072: | Loss 0.83805 | Acc : 49.863\n",
      "Epoch 073: | Loss 0.85235 | Acc : 49.246\n",
      "Epoch 074: | Loss 0.85686 | Acc : 50.241\n",
      "Epoch 075: | Loss 0.86121 | Acc : 50.548\n",
      "Epoch 076: | Loss 0.84491 | Acc : 49.741\n",
      "Epoch 077: | Loss 0.83774 | Acc : 50.046\n",
      "Epoch 078: | Loss 0.82951 | Acc : 50.375\n",
      "Epoch 079: | Loss 0.87556 | Acc : 50.281\n",
      "Epoch 080: | Loss 0.84426 | Acc : 49.976\n",
      "Epoch 081: | Loss 0.84437 | Acc : 50.464\n",
      "Epoch 082: | Loss 0.82645 | Acc : 50.154\n",
      "Epoch 083: | Loss 0.86723 | Acc : 49.824\n",
      "Epoch 084: | Loss 0.86905 | Acc : 49.545\n",
      "Epoch 085: | Loss 0.84910 | Acc : 50.192\n",
      "Epoch 086: | Loss 0.85571 | Acc : 49.957\n",
      "Epoch 087: | Loss 0.85015 | Acc : 49.784\n",
      "Epoch 088: | Loss 0.84663 | Acc : 50.141\n",
      "Epoch 089: | Loss 0.83606 | Acc : 50.203\n",
      "Epoch 090: | Loss 0.83859 | Acc : 48.698\n",
      "Epoch 091: | Loss 0.85877 | Acc : 50.401\n",
      "Epoch 092: | Loss 0.84835 | Acc : 49.863\n",
      "Epoch 093: | Loss 0.85612 | Acc : 49.740\n",
      "Epoch 094: | Loss 0.83555 | Acc : 49.905\n",
      "Epoch 095: | Loss 0.85679 | Acc : 50.324\n",
      "Epoch 096: | Loss 0.84620 | Acc : 50.463\n",
      "Epoch 097: | Loss 0.84624 | Acc : 50.099\n",
      "Epoch 098: | Loss 0.83190 | Acc : 50.039\n",
      "Epoch 099: | Loss 0.84260 | Acc : 50.213\n",
      "Epoch 100: | Loss 0.85506 | Acc : 50.189\n"
     ]
    }
   ],
   "source": [
    "for e in range( 1, EPOCHS + 1 ):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc =0 \n",
    "    # data 를 GPU 로 전달해줌 \n",
    "    for X_batch, y_batch in dataloader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device).type(torch.cuda.FloatTensor)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    \n",
    "    # Check point 를 저장한다. \n",
    "    torch.save({\n",
    "        'epoch': e,\n",
    "        'model_state_dict': model.state_dict(),# 모델의 파라미터 저장 \n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': epoch_loss,\n",
    "        }, f\"saved/checkpoint_model_{e}_{epoch_loss/len(dataloader)}_{epoch_acc/len(dataloader)}.pt\")\n",
    "    print(f'Epoch {e+0:03}: | Loss {epoch_loss/len(dataloader):.5f} | Acc : {epoch_acc/len(dataloader):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95929691-f203-4bc1-b58c-22cdf5b9f751",
   "metadata": {},
   "source": [
    "## Pre-trained Model\n",
    "\n",
    "- 사전에 학습된 모델을 의미하고 유사한 문제를 학습한 모델로부터 좋은 초기값을 얻기 위해서 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbead0b0-67cc-4b8e-94fa-44e11d183af0",
   "metadata": {},
   "source": [
    "## Transfer Learning \n",
    "\n",
    "- 기존에 학습된 파라미터를 새로운 문제에 \"전이\" 시키도록 학습\n",
    "\n",
    "- 다른 데이터셋으로 만든 모델을 현재 데이터에 적용\n",
    "\n",
    "- 일반적으로 대용량 데이터셋으로 만들어진 모델의 성능 좋다\n",
    "\n",
    "- backbone architecture가 잘 학습된 모델에서 일부분만 변경하여 학습을 수행\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951c9391-9fb6-4b74-9242-b774434ce405",
   "metadata": {},
   "source": [
    "## Freezing\n",
    "\n",
    "- pre-trained model을 활용시 모델의 일부분을 frozen 시킴 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea274c3-522f-437c-b2f7-c7ff5372c154",
   "metadata": {},
   "source": [
    "### Pretrained Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8d2e4076-03dd-4f35-9532-d435188032c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to C:\\Users\\asy10/.cache\\torch\\hub\\checkpoints\\vgg16-397923af.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f9bd151c29449548a65b89479410505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/528M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "vgg = models.vgg16(pretrained=True).to(device)\n",
    "\n",
    "print(vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e22a11c5-82ba-4232-8aa1-47fd12fa2d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 244, 244]           1,792\n",
      "              ReLU-2         [-1, 64, 244, 244]               0\n",
      "            Conv2d-3         [-1, 64, 244, 244]          36,928\n",
      "              ReLU-4         [-1, 64, 244, 244]               0\n",
      "         MaxPool2d-5         [-1, 64, 122, 122]               0\n",
      "            Conv2d-6        [-1, 128, 122, 122]          73,856\n",
      "              ReLU-7        [-1, 128, 122, 122]               0\n",
      "            Conv2d-8        [-1, 128, 122, 122]         147,584\n",
      "              ReLU-9        [-1, 128, 122, 122]               0\n",
      "        MaxPool2d-10          [-1, 128, 61, 61]               0\n",
      "           Conv2d-11          [-1, 256, 61, 61]         295,168\n",
      "             ReLU-12          [-1, 256, 61, 61]               0\n",
      "           Conv2d-13          [-1, 256, 61, 61]         590,080\n",
      "             ReLU-14          [-1, 256, 61, 61]               0\n",
      "           Conv2d-15          [-1, 256, 61, 61]         590,080\n",
      "             ReLU-16          [-1, 256, 61, 61]               0\n",
      "        MaxPool2d-17          [-1, 256, 30, 30]               0\n",
      "           Conv2d-18          [-1, 512, 30, 30]       1,180,160\n",
      "             ReLU-19          [-1, 512, 30, 30]               0\n",
      "           Conv2d-20          [-1, 512, 30, 30]       2,359,808\n",
      "             ReLU-21          [-1, 512, 30, 30]               0\n",
      "           Conv2d-22          [-1, 512, 30, 30]       2,359,808\n",
      "             ReLU-23          [-1, 512, 30, 30]               0\n",
      "        MaxPool2d-24          [-1, 512, 15, 15]               0\n",
      "           Conv2d-25          [-1, 512, 15, 15]       2,359,808\n",
      "             ReLU-26          [-1, 512, 15, 15]               0\n",
      "           Conv2d-27          [-1, 512, 15, 15]       2,359,808\n",
      "             ReLU-28          [-1, 512, 15, 15]               0\n",
      "           Conv2d-29          [-1, 512, 15, 15]       2,359,808\n",
      "             ReLU-30          [-1, 512, 15, 15]               0\n",
      "        MaxPool2d-31            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-32            [-1, 512, 7, 7]               0\n",
      "           Linear-33                 [-1, 4096]     102,764,544\n",
      "             ReLU-34                 [-1, 4096]               0\n",
      "          Dropout-35                 [-1, 4096]               0\n",
      "           Linear-36                 [-1, 4096]      16,781,312\n",
      "             ReLU-37                 [-1, 4096]               0\n",
      "          Dropout-38                 [-1, 4096]               0\n",
      "           Linear-39                    [-1, 1]           4,097\n",
      "================================================================\n",
      "Total params: 134,264,641\n",
      "Trainable params: 134,264,641\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.68\n",
      "Forward/backward pass size (MB): 258.50\n",
      "Params size (MB): 512.18\n",
      "Estimated Total Size (MB): 771.36\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(vgg, (3,244,244))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "df360a4a-3c65-4246-a169-eb9ab83b11e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1, bias=True)\n",
      "  )\n",
      "  (fc): Linear(in_features=1000, out_features=1, bias=True)\n",
      ")\n",
      "features Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): ReLU(inplace=True)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (6): ReLU(inplace=True)\n",
      "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): ReLU(inplace=True)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU(inplace=True)\n",
      "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (13): ReLU(inplace=True)\n",
      "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): ReLU(inplace=True)\n",
      "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): ReLU(inplace=True)\n",
      "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (20): ReLU(inplace=True)\n",
      "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (22): ReLU(inplace=True)\n",
      "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (25): ReLU(inplace=True)\n",
      "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (27): ReLU(inplace=True)\n",
      "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (29): ReLU(inplace=True)\n",
      "  (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "features.0 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "features.1 ReLU(inplace=True)\n",
      "features.2 Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "features.3 ReLU(inplace=True)\n",
      "features.4 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "features.5 Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "features.6 ReLU(inplace=True)\n",
      "features.7 Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "features.8 ReLU(inplace=True)\n",
      "features.9 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "features.10 Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "features.11 ReLU(inplace=True)\n",
      "features.12 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "features.13 ReLU(inplace=True)\n",
      "features.14 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "features.15 ReLU(inplace=True)\n",
      "features.16 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "features.17 Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "features.18 ReLU(inplace=True)\n",
      "features.19 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "features.20 ReLU(inplace=True)\n",
      "features.21 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "features.22 ReLU(inplace=True)\n",
      "features.23 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "features.24 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "features.25 ReLU(inplace=True)\n",
      "features.26 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "features.27 ReLU(inplace=True)\n",
      "features.28 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "features.29 ReLU(inplace=True)\n",
      "features.30 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "avgpool AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "classifier Sequential(\n",
      "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Dropout(p=0.5, inplace=False)\n",
      "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (4): ReLU(inplace=True)\n",
      "  (5): Dropout(p=0.5, inplace=False)\n",
      "  (6): Linear(in_features=4096, out_features=1, bias=True)\n",
      ")\n",
      "classifier.0 Linear(in_features=25088, out_features=4096, bias=True)\n",
      "classifier.1 ReLU(inplace=True)\n",
      "classifier.2 Dropout(p=0.5, inplace=False)\n",
      "classifier.3 Linear(in_features=4096, out_features=4096, bias=True)\n",
      "classifier.4 ReLU(inplace=True)\n",
      "classifier.5 Dropout(p=0.5, inplace=False)\n",
      "classifier.6 Linear(in_features=4096, out_features=1, bias=True)\n",
      "fc Linear(in_features=1000, out_features=1, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for name, layer in vgg.named_modules():\n",
    "    print(name, layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b8a53538-b2a2-49ac-8ee7-2212a3050895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1, bias=True)\n",
       "  )\n",
       "  (fc): Linear(in_features=1000, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg.fc = torch.nn.Linear(1000,1)\n",
    "vgg.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b25796b7-d91b-474e-a117-488ad3bbc587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1, bias=True)\n",
       "  )\n",
       "  (fc): Linear(in_features=1000, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vgg.classifier._modules['6'] = torch.nn.Linear(4096,1) # 마지막 레이어 이름 변경해서 최종 output featrues = 1로 만들기 \n",
    "#vgg.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "caeede7d-f1a5-436c-bc43-cd4a9426b3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch \n",
    "\n",
    "dataset = datasets.ImageFolder(root=\"./data/PetImages\",\n",
    "\t\t\t\ttransform=transforms.Compose([\n",
    "                transforms.Resize(244),\n",
    "                transforms.CenterCrop(244),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "        \t\t\t\t std = [0.5, 0.5, 0.5])\n",
    "                ]))\n",
    "                \n",
    "dataloader = torch.utils.data.DataLoader(dataset,batch_size=8,shuffle=True,num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bda9fb1f-b107-4558-8c8f-990122336478",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torchvision import models\n",
    "\n",
    "class MyNewNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNewNet, self).__init__()\n",
    "        self.vgg19 = models.vgg19(pretrained=True)\n",
    "        self.linear_layers = nn.Linear(1000,1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.vgg19(x)\n",
    "        return self.linear_layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0fef2f32-a105-4af9-b927-40cf80071cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = MyNewNet()\n",
    "my_model = my_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4a0a1b8a-a49e-4604-ae8d-df24614887a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyNewNet(\n",
      "  (vgg19): VGG(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (6): ReLU(inplace=True)\n",
      "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (8): ReLU(inplace=True)\n",
      "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (11): ReLU(inplace=True)\n",
      "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (13): ReLU(inplace=True)\n",
      "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (15): ReLU(inplace=True)\n",
      "      (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (17): ReLU(inplace=True)\n",
      "      (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (20): ReLU(inplace=True)\n",
      "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (22): ReLU(inplace=True)\n",
      "      (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (24): ReLU(inplace=True)\n",
      "      (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (26): ReLU(inplace=True)\n",
      "      (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (29): ReLU(inplace=True)\n",
      "      (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (31): ReLU(inplace=True)\n",
      "      (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (33): ReLU(inplace=True)\n",
      "      (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (35): ReLU(inplace=True)\n",
      "      (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "      (4): ReLU(inplace=True)\n",
      "      (5): Dropout(p=0.5, inplace=False)\n",
      "      (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (linear_layers): Linear(in_features=1000, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(my_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2f118714-b776-4834-861e-96ba6b01de9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in my_model.parameters(): # frozeen\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c3a1513e-cd87-4727-8eed-0b4ac10b5e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in my_model.linear_layers.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "21bf3a9e-0f86-4385-b68a-7ef7b9863e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyNewNet(\n",
       "  (vgg19): VGG(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace=True)\n",
       "      (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (17): ReLU(inplace=True)\n",
       "      (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (20): ReLU(inplace=True)\n",
       "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (22): ReLU(inplace=True)\n",
       "      (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (24): ReLU(inplace=True)\n",
       "      (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (26): ReLU(inplace=True)\n",
       "      (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (29): ReLU(inplace=True)\n",
       "      (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (31): ReLU(inplace=True)\n",
       "      (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (33): ReLU(inplace=True)\n",
       "      (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (35): ReLU(inplace=True)\n",
       "      (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (linear_layers): Linear(in_features=1000, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "538979b2-a0c2-453b-97f6-79df06acfc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ac437438-c056-4ea8-86a7-3ba615cb6e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 3, 244, 244])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape # batch, 3 , 244 , 244"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8c8404aa-a7ab-42fc-9db4-582d7d7fae7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2265],\n",
       "        [-0.5768],\n",
       "        [-0.1067],\n",
       "        [ 0.4275],\n",
       "        [ 0.7496],\n",
       "        [-0.5965],\n",
       "        [ 0.0294],\n",
       "        [-1.3035]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model(x[0].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fd7415f4-2c96-42a2-b863-e5f5b325f28d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "def001bf-908b-472d-bf52-540fa32be1d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0535, -0.0493, -0.0679],\n",
       "         [ 0.0153,  0.0451,  0.0021],\n",
       "         [ 0.0362,  0.0200,  0.0199]],\n",
       "\n",
       "        [[ 0.0170,  0.0554, -0.0062],\n",
       "         [ 0.1416,  0.2271,  0.1376],\n",
       "         [ 0.1200,  0.2003,  0.0921]],\n",
       "\n",
       "        [[-0.0449,  0.0127, -0.0145],\n",
       "         [ 0.0597,  0.1395,  0.0541],\n",
       "         [-0.0010,  0.0583, -0.0297]]], device='cuda:0')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(my_model.vgg19.features._modules['0'].parameters())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2f7a8c66-89aa-45e7-b78c-e96235847f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0166, -0.0205, -0.0130, -0.0253, -0.0272, -0.0042,  0.0126,  0.0103,\n",
       "        -0.0168,  0.0203], device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = my_model.linear_layers.parameters() # frozeen 시키지 않음 /\n",
    "next(it)[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8519b406-10d2-476b-aca0-82be190255b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1372481-b681-411c-af00-0cbb4ba89a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "    \n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc*100)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "my_model = MyNewNet()\n",
    "my_model = my_model.to(device)\n",
    "\n",
    "for param in my_model.parameters(): #parameters frozeen\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for param in my_model.linear_layers.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(my_model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for e in range( 1, EPOCHS + 1 ):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc =0 \n",
    "    # data 를 GPU 로 전달해줌 \n",
    "    for X_batch, y_batch in dataloader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device).type(torch.cuda.FloatTensor)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        y_pred = my_model(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    \n",
    "    # Check point 를 저장한다. \n",
    "    torch.save({\n",
    "        'epoch': e,\n",
    "        'model_state_dict': my_model.state_dict(),# 모델의 파라미터 저장 \n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': epoch_loss,\n",
    "        }, f\"saved/checkpoint_model_{e}_{epoch_loss/len(dataloader)}_{epoch_acc/len(dataloader)}.pt\")\n",
    "    print(f'Epoch {e+0:03}: | Loss {epoch_loss/len(dataloader):.5f} | Acc : {epoch_acc/len(dataloader):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a56f33c-3e90-4f5e-a0bd-06d682cee298",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
